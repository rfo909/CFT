# License
<<< EOF
#
# CFT - an interactive programmable shell for automation 
# Copyright (C) 2020-2025 Roar Foshaug
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, version 3 of the License.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <https://www.gnu.org/licenses/>
#
>>> EOF
/License

# Readme!
<<< EOF
ElasticSearch / Kibana / Logstash install and configure
########################################################

- For Linux only
- Modify depending on where install files are located

Set up a number of VM's and ensure password-less access
via SSH, and that the SSH user is added to 
/etc/sudoers.

The first time running, you will have to enter your host
names and then the SSH user name.

This is remembered in the internal database. A four hour
timeout since last access will ask you to confirm the data.

Then run
--------

- ES1 / ElasticSearchComplete       Works!

- KIB1 / InstallKibanaAll           Works!
- KIB2 / ConfigureKibanaAll         Works!

- LS1 / InstallLogstashAll          Works!

- TestLogstashPipeline              Works!

Logstash pipelines must be configured outside this script,
using the code from TestLogstashPipeline as template, for
getting multiple pipelines correctly configured.

To configure Logstash
----------------------
See function ExamplePLs which pushes some example pipelines to
a single host running Logstash. To push config to all defined
hosts with Logstash, run PushLogstashConfigAll.

To stop and start logstash on all Logstash hosts:

- StopLogstash
- StartLogstash

Host definitions
----------------
When installing, you are asked to enter lists of host names:
- ElasticSearch host names = master nodes and worker nodes
- Master hosts
- Logstash hosts
- Kibana hosts
- SSH user name

To inspect or modify the host definitions, run

GetConfigData(true)


>>> EOF
/Readme

Input("ssh target user@host").get
//GetTarget

"elasticsearch-7.16.3-amd64.deb"
//ESImage

"kibana-7.16.3-amd64.deb"
//KibanaImage



# Get, set or confirm config data
# --
    P(1,false) => forceUpdate

    Db2:Get("ElasticSearch","Config") => dict

    save=false
    
    if (dict==null) {
        forceUpdate=true
        dict=Dict
    }

    # one week timeout for settings
    if (forceUpdate || Util:HasTimedOut("ElasticSearch.ConfigCheck", 7*24*3600)) {
        Input("All ElasticSearch host names (masters and data nodes) - space-separated") => inp
        inp.clear.setCurr(dict.get("hosts",List).concat(" "))
        dict.set("hosts", inp.get.split)
    
        Input("Master host names - space-separated") => inp
        inp.clear.setCurr(dict.get("masterHosts",List).concat(" "))
        dict.set("masterHosts", inp.get.split)
    
        Input("Logstash host names - space-separated") => inp
        inp.clear.setCurr(dict.get("logstashHosts",List).concat(" "))
        dict.set("logstashHosts", inp.get.split)
    
        Input("Kibana host names - space-separated") => inp
        inp.clear.setCurr(dict.get("kibanaHosts",List).concat(" "))
        dict.set("kibanaHosts", inp.get.split)
    
        Input("SSH user name") => inp
        inp.clear.setCurr(dict.get("user",""))
        dict.set("user", inp.get)

        Lib:Header("Current config")
        Util:ShowDict(dict,true)

        error(!Lib:Confirm,"Aborting")

        # Refresh time mark
        Db2:Set("ElasticSearch","Config",dict)

        save=true
    }

    Util:SetTimeMark("ElasticSearch.ConfigCheck")

    dict
//GetConfigData



# Show config data
# --
    Util:ShowDict(GetConfigData,true)
/ShowConfigData



# Hosts in cluster
# --
    GetConfigData.hosts
/hosts


# Master hosts
# --
    GetConfigData.masterHosts
/masterHosts



# Logstash hosts
# --
    GetConfigData.logstashHosts
/logstashHosts



# Kibana hosts
    GetConfigData.kibanaHosts
/kibanaHosts




# SSH user
# --
    GetConfigData.user
/user











# Lookup ip address
# --
    P(1,"elk03.v")=>host
    foundName=false
    result=null
    Lib:run("nslookup",host).stdout->line
        if(line.startsWith("Name:") && line.contains(host)) {
            foundName=true
            continue
        }
        if (foundName && line.startsWith("Address:")) {
            result=line.after(":").trim
        }
    |
    error(result==null,"Could not resolve " + host)
    result
//GetIp


# Ensure NFS client ok
# --
    P(1,GetTarget)=>target
    P(2,"")=>prefix
    println(prefix+"Ensuring nfs-common installed")
    
    println(prefix+"Running apt-get update")
    SSH:sudo(target,"apt-get update")
    println(prefix+"Installing nfs-common")
    SSH:sudo(target,"apt-get install -y nfs-common")
//EnsureNFSClient


# Ensure /mnt/storage ok
# --
    P(1,GetTarget)=>target
    P(2,"")=>prefix

    println(prefix+"Checking /mnt/storage/ISO ok")

    EnsureNFSClient(target,prefix+"   ")

    SSH:sudo(target,"mount -a")
    SSH:sudo(target,"ls /mnt/storage/ISO", true).get("exitCode") != 0 => notFound
    if (notFound) {
        println(prefix+"Creating /mnt/storage")
        SSH:sudo(target,"mkdir /mnt/storage", true) # ignore errors
        println(prefix+"Updating /etc/fstab")
        SSH:sudo(target,'echo "storage.s:/mnt/storage  /mnt/storage    nfs   rw    0 0" >> /etc/fstab')
        println(prefix+"mount -a")
        SSH:sudo(target,"mount -a")
    }
    SSH:sudo(target,"ls /mnt/storage/ISO", true).get("exitCode") != 0 => notFound
    error(notFound,"Failed to fix /mnt/storage mount on " + target)
//CheckOrFixMntStorage




# Install ElasticSearch
# --
    P(1,GetTarget) =>target
    P(2,"") =>prefix

    println(prefix+"INSTALLING " + target)

    #APTUpdate:run(target,null,true)

    println(prefix+"Checking Java")
    Java:VerifyJava (target, prefix+"   ")

    println("Installing apt-transport-https")
    SSH:sudo(target,"apt-get install -y apt-transport-https")

    CheckOrFixMntStorage(target,prefix+"   ")
    println(prefix+"Installing " + ESImage)
    SSH:sudo(target,"apt-get install -y /mnt/storage/ISO/" + ESImage)

    println("Enabling service")
    SSH:sudo(target,"systemctl enable elasticsearch")

//InstallElasticSearch  


# Set up ElasticSearch configuration file
# --
    P(1,GetTarget) => target
    P(2,List(target)) => masterHosts
    P(3,"")=>prefix

    target.after("@") => nodeHost
    GetIp(nodeHost) => nodeHostIp

    nodeHost.before(".") => nodeName

    isMasterHost=""+masterHosts.contains(nodeHost)
    isDataHost=""+(!masterHosts.contains(nodeHost))

    masterHosts->host
        out('"' + host + '"')
    | _.concat(", ") => masterNodes

    masterHosts->host
        out('"' + GetIp(host) + '"')
    | _.concat(", ") => masterNodesIp

    hosts->host
        out('"' + host + '"')
    | _.concat(", ") => allNodes

    hosts->host
        out('"' + GetIp(host) + '"')
    | _.concat(", ") => allNodesIp

    SymDict(nodeHost,nodeHostIp,
        nodeName,isMasterHost,isDataHost,
        masterNodes,masterNodesIp,allNodes,allNodesIp
    ).mergeCodes=>data

    # IP-numbers vs host names
    # ------------------------
    # The clue here is that by using IP addresses for network.host as well as
    # in the initial_master_nodes and the unicast.hosts, everything works, as the
    # check on network.host is LITERAL. With this config, we can NOT do
    # curl to localhost, only to the IP-address. Doing CURL from outside, we can also
    # not use host names, but have to use IP-addresses. Because the network.host
    # field for Elastic is about ACCESS CONTROL and it is taken literally.

    Sequence(
        @ cluster.name: mycluster
        @ node.name: ${nodeName}
        @ node.data: ${isDataHost}
        @ node.ingest: ${isDataHost}
        @ node.master: ${isMasterHost}
    @ network.host: "${nodeHostIp}"
        @ http.port: 9200
        @ path.data: /var/lib/elasticsearch
        @ path.logs: /var/log/elasticsearch
        @ cluster.initial_master_nodes: [ ${masterNodesIp} ]
        @ discovery.zen.ping.unicast.hosts: [ ${allNodesIp} ]
    )->line
        out(line.merge(data))
    | => config

    Lib:TmpFile("elasticsearch","yml") => f 
    f.create(config)

    println(prefix+"Configuration for " + target)
    println("---")
    f.read->line println(line) 
    |
    println("---")

    SSH:copy(f,target,"./elasticsearch.yml")
    SSH:sudo(target,"cp ./elasticsearch.yml /etc/elasticsearch")
    f.delete

    println("Creating directories for data and log")
    SSH:sudo(target,"mkdir -p /var/lib/elasticsearch")
    SSH:sudo(target,"mkdir -p /var/log/elasticsearch")

    SSH:sudo(target,"chmod 755 /var/lib/elasticsearch")
    SSH:sudo(target,"chmod 755 /var/log/elasticsearch")

    SSH:sudo(target,"chown elasticsearch /var/lib/elasticsearch")
    SSH:sudo(target,"chown elasticsearch /var/log/elasticsearch")

//InstallElasticSearchConfig




# Stop ElasticSearch nodes
# --
    hosts->host
        target=user+"@"+host
        println("STOPPING elasticsearch on " + target)
        ##SSH:sudo(target,"systemctl stop elasticsearch")
        SSH:sudo(target,"service elasticsearch stop")
/StopElasticSearch




# Start ElasticSearch nodes
# --
    hosts->host
        #reject(masterHosts.contains(host))
        println("STARTING elasticsearch on " + host)
        target=user+"@"+host
        SpawnProcess(SymDict(target),{
            SSH:sudo(target,"systemctl start elasticsearch")
        }) => proc out(proc)
    | => processes

    processes->proc
        proc.wait
        println("Started " + proc.data.target)
  |
    println("All done!")
/StartElasticSearch



# Complete install ElasticSearch 
# --
    
    ShowConfigData
    readLine("Press ENTER to continue")

    hosts->host
        target=user+"@"+host
        InstallElasticSearch(target)
        InstallElasticSearchConfig(target,masterHosts)
    |
    StopElasticSearch
    println
    StartElasticSearch
/ElasticSearchComplete




# Check install remote
# --
    P(1,GetTarget) => target

    # Only works using IP-address, not "localhost", see text in
    # the InstallElasticSearchConfig function

    target.after("@") => host
    GetIp(host) => ip
    SSH:run(target,"curl -XGET 'http://"+ip+":9200/_cluster/state?pretty'").stdout
/CheckInstallRemote



    
# Install kibana
# --
    kibanaHosts->host
        target=user+"@"+host
        println("INSTALLING kibana " + host)
        CheckOrFixMntStorage(target)

        println("Installing " + KibanaImage)
        SSH:sudo(target,"apt-get install -y /mnt/storage/ISO/" + KibanaImage)

        println("Enabling service")
        SSH:sudo(target,"systemctl enable kibana")
/InstallKibanaAll


# Configure Kibana all
# 
# Using IP-addresses to connect to the master nodes!
#
# Port 5601
# Note: Kibana uses a bit of time after restart, to become available!
# --
    kibanaHosts->host
        target=user+"@"+host
        
        println("Configure Kibana " + host)


        # Create config
        
        Inner {
            masterHosts->host 
                out('"http://' + GetIp(host) + ':9200"')
            | _.concat(", ")
        } => masterNodesIp

        SymDict(masterNodesIp).mergeCodes => data

        println("Creating log dir /var/log/kibana")
        SSH:sudo(target,"mkdir -p /var/log/kibana")
        SSH:sudo(target,"chown kibana /var/log/kibana")


        # For Kibana, server.host 0.0.0.0 means all, also
        # when called using host name instead of IP address
        
        Inner {
            Sequence(
                @ server.host: "0.0.0.0"
                @ server.port: 5601
                @ logging.dest: /var/log/kibana/kibana.log
                #@ logging.verbose: true
                @ elasticsearch.hosts: [ ${masterNodesIp} ]
            )->line
                out(line.merge(data))
        } => config

        Lib:TmpFile("kibana","yml") => f
        f.create(config)

        println("Creating kibana.yml")
        println("---")
        { f.read->line println(line) }
        println("---")

        SSH:copy(f,target,"./kibana.yml")
        SSH:sudo(target,"cp ./kibana.yml /etc/kibana/kibana.yml")

        f.delete
    |
    println("Restarting kibana")
    StopKibana
    println
    StartKibana
    Lib:Header("http://" + kibanaHosts.first + ":5601")
    true
/ConfigureKibanaAll


# Stop kibana
# --
    kibanaHosts->host
        target=user+"@"+host
        println("STOPPING kibana " + host)
        SSH:sudo(target,"systemctl stop kibana")
/StopKibana

        
    
# Start kibana
# --
    kibanaHosts->host
        target=user+"@"+host
        println("STARTING kibana " + host)
        SSH:sudo(target,"systemctl start kibana")
/StartKibana







# Install Logstash - enables service, but does not start
# --
    P(1,GetTarget) =>target
    P(2,"") =>prefix

    println(prefix+"INSTALLING logstash " + target)
    # Check if logstash already installed
    SSH:sudo (target, "systemctl status logstash.service", true).get("exitCode")!=4 =>found
    if (found) {
        println(prefix+"Logstash already installed")
    } else {
        # Requires java 8, 11 or 14
        println(prefix+"Setting up logstash")
        Java:VerifyJava (target, prefix+"   ")

        List(
            'wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -',
            'apt-get install apt-transport-https',
            'echo "deb https://artifacts.elastic.co/packages/7.x/apt stable main" | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.list',
            'sudo apt-get update && sudo apt-get install logstash',
            'systemctl enable logstash.service'
        ) =>cmd

        println(prefix+"Installing logstash")
        SSH:sudo (target, cmd)
    }
    println(prefix+"Enabling logstash")
    SSH:sudo (target,"systemctl enable logstash")
/InstallLogstash


# Install logstash for all logstashHosts
#
# Note: configuration not included, just remember to use IP addresses of
# the ElasticSearch cluster nodes!!
# --
    logstashHosts->host
        target=user+"@"+host
        InstallLogstash(target)
/InstallLogstashAll


# Stop logstash
# --
    logstashHosts->host
        println("STOPPING logstash " + host)
        target=user+"@"+host
        SSH:sudo(target,"systemctl stop logstash",true)
/StopLogstash


    
# Start logstash
# --
    logstashHosts->host
        println("STARTING logstash " + host)
        target=user+"@"+host
        SSH:sudo(target,"systemctl start logstash")
/StartLogstash



# Clear logstash pipelines
# --
    Db2Obj:DeleteCollection("LogstashPipeline")
/ClearLogstashPipelines




# Add logstash pipeline
# --
    P(1) => pipelineName
    P(2) => pipelineJSON
    P(3) => esHostsMergeCode

    # Create esHosts merge value
    masterHosts->h out('"' + GetIp(h) + ':9200"') | _.concat(", ") => esHosts
    Dict.set(esHostsMergeCode, esHosts).mergeCodes => data

    # Merge esHosts into JSON
    pipelineJSON->line out(line.merge(data)) | _=> pipelineJSON

    # Store in database
    Db2Obj:AddObject("LogstashPipeline", SymDict(pipelineName, pipelineJSON))
/AddLogstashPipeline




# Example logstash pipeline
#
# Add example logstash pipeline, to scan txt files from a 
# directory on the server. Then run PushLogstashConfig to update
# single logstash target. Log in to the target, sudo, then cd to /etc/logstash,
# then run the <pipelineName>.sh script to run logstash in foreground, 
# to test configuration file.
#
# Or: service logstash start
# --
    P(1,"test1")=>pipelineName
    P(2,"10-30-rfo")=>indexLifePolicy

    targetIndex=pipelineName

    Sequence(
        @ input {
        @     file {
        @          path => [ "/home/roar/logs/*.txt" ]
        @     }
        @ }
        @ filter {
        @ }
        @ output {
        @     elasticsearch {
        @         hosts => [ ${ELKMasterHosts} ]
        @         ilm_enabled => true
        @         ilm_rollover_alias => "<<targetIndex>>"
        @         ilm_policy => "<< indexLifePolicy >>"
        ##@         data_stream => "true"
        ##@           index => "<<targetIndex>>"
        @     }
        @     stdout { codec => rubydebug }
        @ }
    ).mergeExpr => json
    AddLogstashPipeline(pipelineName, json, "ELKMasterHosts")
/AddExampleLogstashPipeline




# Example logstash pipeline for processing beats data
# --
    P(1,"test2")=>pipelineName
    P(2,"10-30-rfo")=>indexLifePolicy

    targetIndex=pipelineName

    Sequence(
        @ input {
        @     beats {
        @          port => 5044
        @     }
        @ }
        @ filter {
        @ }
        @ output {
        @     elasticsearch {
        @         hosts => [ ${ELKMasterHosts} ]
        @         ilm_enabled => true
        @         ilm_rollover_alias => "<<targetIndex>>"
        @         ilm_policy => "<< indexLifePolicy >>"
        @     }
        @     stdout { codec => rubydebug }
        @ }
    ).mergeExpr => json
    AddLogstashPipeline(pipelineName, json, "ELKMasterHosts")
/AddExampleLogstashPipelineBeats


# Add Example logstash pipelines for testing, and push to Logstash host
# Does not start or stop logstash service on target host.
# --
    P(1,GetTarget)=>target

    ClearLogstashPipelines
    AddExampleLogstashPipeline
    AddExampleLogstashPipelineBeats

    PushLogstashConfig(target)
/ExamplePLs


# Push updated logstash config to target host
# --
    P(1,GetTarget) => target

    println("PushLogstashConfig " + target)

    list = Db2Obj:FindObjects("LogstashPipeline")
    error(list.empty,"No Logstash pipelines have been added")

    pipelinesYml = List
    list->x
        p=x.value
        #Util:ShowDict(p,true) error("x")

        # Add logstash.yml configuration for pipeline
        # --
        p.mergeCodes => data
        {
            Sequence(
                @@- pipeline.id: ${pipelineName}
                @@  pipeline.workers: 1
                @@  path.config: "/etc/logstash/conf.d/${pipelineName}.conf"
            ) -> line 
                pipelinesYml.add(line.merge(data))
        }
        # Create pipeline config file
        # --
        Lib:TmpFile(p.get("pipelineName"),"conf") => f
        f.create(p.get("pipelineJSON"))
    
        fname=p.get("pipelineName")+".conf"
        
        println("Deploying " + fname)
        println("---")
        f.read->line println(line) |
        println("---")
        SSH:copy(f,target,"./"+fname)
        SSH:sudo(target,"cp ./"+fname+" /etc/logstash/conf.d")
        f.delete

        # Also create test script for running pipeline interactively
        # --
        pipelineName=p.get("pipelineName")
        Lib:TmpFile(pipelineName,"sh")=>f
        SSH:run(target,"which bash").stdout.first => bash

        Sequence(
            "#!"+bash
            "/usr/share/logstash/bin/logstash -f /etc/logstash/conf.d/" + pipelineName + ".conf"
        ) =>lines
        f.create(lines)
        SSH:copy(f,target,"./"+pipelineName+".sh")
        SSH:sudo(target,"cp ./"+pipelineName+".sh /etc/logstash")
        SSH:sudo(target,"chmod +x /etc/logstash/" + pipelineName + ".sh")
        println("Created /etc/logstash/" + pipelineName + ".sh")
        f.delete
    |


    # The pipelines.yml default points to conf.d/*.conf
    #
    # Still, this is cleaner, as it avoid problems with old
    # conf-files.

    Lib:TmpFile("pipelines","yml") => f

    f.create(pipelinesYml)
    println("Deploying pipelines.yml")
    println("---")
    f.read->line println(line) |
    println("---")
    SSH:copy(f,target,"./pipelines.yml")
    SSH:sudo(target,"cp ./pipelines.yml /etc/logstash")
    f.delete

    # Logstash.yml
    # --
    Lib:TmpFile("logstash","yml") => f
    println("Deploying logstash.yml")
    f.create(List(
        "path.data: /var/lib/logstash",
        "path.logs: /var/log/logstash"
    ))
    SSH:copy(f,target,"./logstash.yml")
    SSH:sudo(target,"cp ./logstash.yml /etc/logstash")
    f.delete

    "ok"
/PushLogstashConfig



# Update logstash config all 
# --
    logstashHosts->host
        Lib:Header("Update logstash " + host)
        target=user+"@"+host
        PushLogstashConfig(target)
    |
    StopLogstash
    println
    StartLogstash
/PushLogstashConfigAll

    
    

        
    

ElasticSearchComplete 
/ES1




CheckInstallRemote(user + "@" + masterHosts.first)
/ES2



InstallKibanaAll
/KIB1



ConfigureKibanaAll
/KIB2



InstallLogstashAll
/LS1




# Add example logstash pipeline
# It receives beats data and insert them unmodified into Elastic in index beatstest-*
# --
    ClearLogstashPipelines
<<<<<<<<<<<<<<<<< EOF
input {
    beats {
        port => "5044"
    }
}
output {
    elasticsearch {
        index => "beatstest-%{+YYYY.MM.dd}"
        hosts => [ ${esHosts} ]
    }
}
>>>>>>>>>>>>>>>>> EOF
    => json

    AddLogstashPipeline("test", json, "esHosts")
    PushLogstashConfigAll
/TestLogstashPipeline




